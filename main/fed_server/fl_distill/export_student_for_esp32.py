#!/usr/bin/env python3
"""
Export student encoder -> TFLite + export classifier weights to C header + bin.

Usage:
  python export_student_for_esp32.py \
      --student_h5 student_distilled.h5 \
      --encoder_tflite student_encoder_fp32.tflite \
      --classifier_h classifier_weights.h \
      --classifier_bin classifier_weights.bin \
      --feature_layer_name student_features \
      --quantize_int8 0 \
      --representative_dir ./rep_data

Notes:
 - script assumes student model has a Dense named as provided by --feature_layer_name that outputs features,
   and the final logits Dense is the classifier (or final layer).
 - For int8 quantization, provide representative dataset dir (--representative_dir).
"""
#!/usr/bin/env python3
"""
Export student encoder -> TFLite + export classifier weights to C header + bin.
"""

# !/usr/bin/env python3
"""
Export student encoder -> TFLite + export classifier weights to C header + bin.
"""

import sys
import subprocess
 
# 现在安全导入
import tensorflow as tf
import numpy as np
import argparse
import os


def save_c_array_floats(arr: np.ndarray, varname: str, filename: str, fmt="%.8ff"):
    """
    Write a C header with float array and metadata.
    arr: numpy array (any shape)
    varname: base varname (we'll write varname_data, varname_dims, varname_len)
    """
    with open(filename, "w") as f:
        f.write("// Auto-generated by export_student_for_esp32.py\n\n")
        f.write("#pragma once\n\n")
        f.write(f"#include <stdint.h>\n\n")
        shape = list(arr.shape)
        total = arr.size
        f.write(f"// shape: {shape}\n")
        f.write(f"static const int {varname}_ndim = {len(shape)};\n")
        f.write(f"static const int {varname}_shape[] = {{{', '.join(map(str, shape))}}};\n")
        f.write(f"static const int {varname}_len = {total};\n\n")
        f.write(f"static const float {varname}_data[{total}] = {{\n")
        # write values (row-major)
        for i, v in enumerate(arr.flatten()):
            f.write(f"  {v:.8e}f")
            if i != total-1:
                f.write(",")
            if (i+1) % 8 == 0:
                f.write("\n")
        f.write("\n};\n")

def main(args):
    # load student model
    student = tf.keras.models.load_model(args.student_h5, compile=False)
    print("[INFO] Loaded student:", args.student_h5)
    # find feature layer and final dense
    # feature layer by name, classifier assumed last Dense
    try:
        feat_layer = student.get_layer(args.feature_layer_name)
    except Exception as e:
        print("[ERROR] cannot find feature layer named", args.feature_layer_name)
        raise

    # Build encoder model: inputs -> feat_layer.output
    encoder = tf.keras.Model(inputs=student.inputs, outputs=feat_layer.output)
    print("[INFO] Encoder model built. Output shape:", encoder.output_shape)

    # Identify classifier layer weights: assume final Dense layer
    # If the final layer is not Dense, try to find layer named 'logits' or last Dense
    classifier_layer = None
    for lyr in reversed(student.layers):
        if isinstance(lyr, tf.keras.layers.Dense):
            classifier_layer = lyr
            break
    if classifier_layer is None:
        raise RuntimeError("No Dense classifier layer found in student model.")
    print("[INFO] Found classifier layer:", classifier_layer.name, "weights shape:", classifier_layer.get_weights()[0].shape)

    weights, bias = classifier_layer.get_weights()  # weights shape (feature_dim, num_classes)
    weights = weights.astype(np.float32)
    bias = bias.astype(np.float32)
    feature_dim, num_classes = weights.shape
    print(f"[INFO] classifier weights shape: {weights.shape}, bias: {bias.shape}")

    # Export encoder to TFLite (FP32)
    converter = tf.lite.TFLiteConverter.from_keras_model(encoder)
    tflite_model = converter.convert()
    with open(args.encoder_tflite, "wb") as f:
        f.write(tflite_model)
    print("[INFO] Saved encoder TFLite (FP32):", args.encoder_tflite)

    # Optional int8 quantization
    if args.quantize_int8:
        if not args.representative_dir:
            raise ValueError("Representative dir required for int8 quant")
        # build representative generator from image files in representative_dir
        def rep_gen():
            import glob
            from PIL import Image
            img_paths = glob.glob(os.path.join(args.representative_dir, "*", "*"))
            for p in img_paths[:1000]:
                im = Image.open(p).convert("RGB").resize(tuple(args.img_size))
                arr = np.array(im).astype(np.float32) / 255.0
                arr = np.expand_dims(arr, 0)
                yield [arr]
        conv = tf.lite.TFLiteConverter.from_keras_model(encoder)
        conv.optimizations = [tf.lite.Optimize.DEFAULT]
        conv.representative_dataset = rep_gen
        conv.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
        conv.inference_input_type = tf.uint8
        conv.inference_output_type = tf.uint8
        tfl_int8 = conv.convert()
        outp = args.encoder_tflite.replace(".tflite", "_int8.tflite")
        with open(outp, "wb") as f:
            f.write(tfl_int8)
        print("[INFO] Saved encoder int8 tflite:", outp)

    # Write classifier weights to C header and binary
    # We'll flatten weights in row-major (feature_dim major: weights[feature_idx * num_classes + class_idx])
    # But most C code finds easier to index as weights[feature_dim][num_classes] in header.
    # Create header with float array
    # create arrays: weights_2d shape (feature_dim, num_classes)
    w_2d = weights.reshape((feature_dim, num_classes))
    # header
    save_c_array_floats(w_2d, varname="classifier_weights", filename=args.classifier_h)
    # bias header appended
    with open(args.classifier_h, "a") as f:
        f.write("\n")
        f.write(f"static const float classifier_bias_data[{bias.size}] = {{\n")
        for i, v in enumerate(bias.flatten()):
            f.write(f"  {v:.8e}f")
            if i != bias.size - 1:
                f.write(",")
            if (i+1) % 8 == 0:
                f.write("\n")
        f.write("\n};\n")

    # Also export a compact binary (float32 little endian) for OTA
    with open(args.classifier_bin, "wb") as f:
        f.write(weights.astype(np.float32).tobytes())
        f.write(bias.astype(np.float32).tobytes())
    print("[INFO] Wrote classifier binary:", args.classifier_bin)
    print("[DONE] feature_dim:", feature_dim, "num_classes:", num_classes)
    print("C header:", args.classifier_h)

if __name__ == "__main__":
    p = argparse.ArgumentParser()
    p.add_argument("--student_h5", default="student.h5")
    p.add_argument("--encoder_tflite", default="student_encoder_fp32.tflite")
    p.add_argument("--classifier_h", default="classifier_weights.h")
    p.add_argument("--classifier_bin", default="classifier_weights.bin")
    p.add_argument("--feature_layer_name", default="student_features")
    p.add_argument("--quantize_int8", type=int, default=0)
    p.add_argument("--representative_dir", default=None)
    p.add_argument("--img_size", nargs=2, type=int, default=[224,224])
    args = p.parse_args()
    main(args)
