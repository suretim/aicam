import numpy as np
from PIL import Image
import tensorflow as tf

# åŠ è½½ encoder æ¨¡å‹ï¼ˆHDF5 æ ¼å¼æˆ–é‡æ–°è®­ç»ƒï¼‰
encoder = tf.keras.models.load_model("encoder_model.h5")

# è®¾ç½®å›¾åƒå¤§å°
img_size = (64, 64)

# å®šä¹‰ compute_prototypes å‡½æ•°
def compute_prototypes(encoder, dataset):
    embeddings = []
    labels = []
    for images, lbls in dataset:
        emb = encoder(images)
        embeddings.append(emb.numpy())
        labels.append(lbls.numpy())
    embeddings = np.concatenate(embeddings)
    labels = np.concatenate(labels)
    prototypes = {}
    for label in np.unique(labels):
        proto_means = embeddings[labels == label].mean(axis=0)
        prototypes[label] = proto_means
    return prototypes

# å®šä¹‰åŸå‹æ¨ç†å‡½æ•°
def predict_prototype(encoder, image, prototypes):
    emb = encoder(tf.expand_dims(image, 0)).numpy()[0]
    distances = {k: np.linalg.norm(emb - v) for k, v in prototypes.items()}
    pred = min(distances, key=distances.get)
    return pred, distances

# åŠ è½½ä½ çš„æµ‹è¯•å›¾åƒ
img = Image.open("new_leaf.jpg").resize(img_size)
img = np.array(img) / 255.0

# åŠ è½½ä½ ä¹‹å‰çš„è®­ç»ƒæ•°æ®é›†
dataset = tf.keras.preprocessing.image_dataset_from_directory(
    "data",
    labels='inferred',
    label_mode='int',
    image_size=img_size,
    batch_size=32
)
class_names = dataset.class_names

# è®¡ç®—ç±»åŸå‹å¹¶è¿›è¡Œæ¨ç†
prototypes = compute_prototypes(encoder, dataset)
pred, dist = predict_prototype(encoder, img, prototypes)

# è¾“å‡ºæ¨ç†ç»“æœ
print(f"âœ… Predicted class: {class_names[pred]}")
print(f"ğŸ“ Distances: {dist}")
